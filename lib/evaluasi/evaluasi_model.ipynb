{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 411us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qv/4r0bgwj92x98njt6rl44cc9m0000gn/T/ipykernel_97142/2480519593.py:121: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[ 'btch ' + str(batch_size_trial) + '-' + ' epoch ' + str(epochs_trial), mse, rounded_up]], columns=['parameter', 'mse', 'akurasi']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 408us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qv/4r0bgwj92x98njt6rl44cc9m0000gn/T/ipykernel_97142/2480519593.py:121: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[ 'btch ' + str(batch_size_trial) + '-' + ' epoch ' + str(epochs_trial), mse, rounded_up]], columns=['parameter', 'mse', 'akurasi']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 405us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qv/4r0bgwj92x98njt6rl44cc9m0000gn/T/ipykernel_97142/2480519593.py:121: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[ 'btch ' + str(batch_size_trial) + '-' + ' epoch ' + str(epochs_trial), mse, rounded_up]], columns=['parameter', 'mse', 'akurasi']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 400us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qv/4r0bgwj92x98njt6rl44cc9m0000gn/T/ipykernel_97142/2480519593.py:121: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[ 'btch ' + str(batch_size_trial) + '-' + ' epoch ' + str(epochs_trial), mse, rounded_up]], columns=['parameter', 'mse', 'akurasi']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 397us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qv/4r0bgwj92x98njt6rl44cc9m0000gn/T/ipykernel_97142/2480519593.py:121: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[ 'btch ' + str(batch_size_trial) + '-' + ' epoch ' + str(epochs_trial), mse, rounded_up]], columns=['parameter', 'mse', 'akurasi']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 415us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qv/4r0bgwj92x98njt6rl44cc9m0000gn/T/ipykernel_97142/2480519593.py:121: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[ 'btch ' + str(batch_size_trial) + '-' + ' epoch ' + str(epochs_trial), mse, rounded_up]], columns=['parameter', 'mse', 'akurasi']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 405us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qv/4r0bgwj92x98njt6rl44cc9m0000gn/T/ipykernel_97142/2480519593.py:121: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[ 'btch ' + str(batch_size_trial) + '-' + ' epoch ' + str(epochs_trial), mse, rounded_up]], columns=['parameter', 'mse', 'akurasi']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 395us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qv/4r0bgwj92x98njt6rl44cc9m0000gn/T/ipykernel_97142/2480519593.py:121: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[ 'btch ' + str(batch_size_trial) + '-' + ' epoch ' + str(epochs_trial), mse, rounded_up]], columns=['parameter', 'mse', 'akurasi']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 389us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qv/4r0bgwj92x98njt6rl44cc9m0000gn/T/ipykernel_97142/2480519593.py:121: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[ 'btch ' + str(batch_size_trial) + '-' + ' epoch ' + str(epochs_trial), mse, rounded_up]], columns=['parameter', 'mse', 'akurasi']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 396us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qv/4r0bgwj92x98njt6rl44cc9m0000gn/T/ipykernel_97142/2480519593.py:121: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[ 'btch ' + str(batch_size_trial) + '-' + ' epoch ' + str(epochs_trial), mse, rounded_up]], columns=['parameter', 'mse', 'akurasi']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 388us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qv/4r0bgwj92x98njt6rl44cc9m0000gn/T/ipykernel_97142/2480519593.py:121: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[ 'btch ' + str(batch_size_trial) + '-' + ' epoch ' + str(epochs_trial), mse, rounded_up]], columns=['parameter', 'mse', 'akurasi']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 418us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qv/4r0bgwj92x98njt6rl44cc9m0000gn/T/ipykernel_97142/2480519593.py:121: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[ 'btch ' + str(batch_size_trial) + '-' + ' epoch ' + str(epochs_trial), mse, rounded_up]], columns=['parameter', 'mse', 'akurasi']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 401us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qv/4r0bgwj92x98njt6rl44cc9m0000gn/T/ipykernel_97142/2480519593.py:121: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[ 'btch ' + str(batch_size_trial) + '-' + ' epoch ' + str(epochs_trial), mse, rounded_up]], columns=['parameter', 'mse', 'akurasi']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 419us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qv/4r0bgwj92x98njt6rl44cc9m0000gn/T/ipykernel_97142/2480519593.py:121: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[ 'btch ' + str(batch_size_trial) + '-' + ' epoch ' + str(epochs_trial), mse, rounded_up]], columns=['parameter', 'mse', 'akurasi']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 407us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qv/4r0bgwj92x98njt6rl44cc9m0000gn/T/ipykernel_97142/2480519593.py:121: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[ 'btch ' + str(batch_size_trial) + '-' + ' epoch ' + str(epochs_trial), mse, rounded_up]], columns=['parameter', 'mse', 'akurasi']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 445us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qv/4r0bgwj92x98njt6rl44cc9m0000gn/T/ipykernel_97142/2480519593.py:121: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[ 'btch ' + str(batch_size_trial) + '-' + ' epoch ' + str(epochs_trial), mse, rounded_up]], columns=['parameter', 'mse', 'akurasi']))\n"
     ]
    }
   ],
   "source": [
    "# General data analysis/plotting\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import math\n",
    "\n",
    "# Data preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "# Neural Net modules\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "import matplotlib\n",
    "\n",
    "df = pd.read_excel(\"data_clean.xlsx\")\n",
    "df = df[['Diagnosis', 'Tindakan', 'SEX', 'UMUR_TAHUN', 'LAMA_DIRAWAT', 'INACBG', 'HARI']]\n",
    "\n",
    "df['DiagnosisCAT'] = df['Diagnosis']\n",
    "df['Diagnosis'] = df['DiagnosisCAT'].astype('category')\n",
    "df['Diagnosis'] = df['Diagnosis'].cat.reorder_categories(df['DiagnosisCAT'].unique(), ordered=True)\n",
    "df['Diagnosis'] = df['Diagnosis'].cat.codes\n",
    "\n",
    "df['TindakanCAT'] = df['Tindakan']\n",
    "df['Tindakan'] = df['TindakanCAT'].astype('category')\n",
    "df['Tindakan'] = df['Tindakan'].cat.reorder_categories(df['TindakanCAT'].unique(), ordered=True)\n",
    "df['Tindakan'] = df['Tindakan'].cat.codes\n",
    "\n",
    "df['HARICAT'] = df['HARI']\n",
    "df['HARI'] = df['HARICAT'].astype('category')\n",
    "df['HARI'] = df['HARI'].cat.reorder_categories(df['HARICAT'].unique(), ordered=True)\n",
    "df['HARI'] = df['HARI'].cat.codes\n",
    "\n",
    "severity = []\n",
    "for index, row in df.iterrows():\n",
    "    if row['INACBG'].split(\"-\")[-1] == \"I\":\n",
    "        severity.append(1)\n",
    "    elif row['INACBG'].split(\"-\")[-1] == \"II\":\n",
    "        severity.append(2)\n",
    "    else:\n",
    "        severity.append(3)\n",
    "\n",
    "df['Severity'] = severity\n",
    "\n",
    "df.dropna(axis=0, inplace=True)\n",
    "\n",
    "X = df[['Diagnosis', 'Tindakan', 'SEX', 'UMUR_TAHUN', 'Severity']].values\n",
    "y = df[['LAMA_DIRAWAT']].values\n",
    "\n",
    "### Sandardization of data ###\n",
    "PredictorScaler=StandardScaler()\n",
    "TargetVarScaler=StandardScaler()\n",
    "\n",
    "# # Storing the fit object for later reference\n",
    "PredictorScalerFit=PredictorScaler.fit(X)\n",
    "TargetVarScalerFit=TargetVarScaler.fit(y)\n",
    "\n",
    "# # Generating the standardized values of X and y\n",
    "X=PredictorScalerFit.transform(X)\n",
    "y=TargetVarScalerFit.transform(y)\n",
    "\n",
    "# Split the data into training and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "batch_size_list=[16, 32, 64, 128]\n",
    "epoch_list  =   [50, 100, 200, 500]\n",
    "\n",
    "SearchResultsData=pd.DataFrame(columns=['parameter', 'mse', 'akurasi'])\n",
    "batch_size =[]\n",
    "epoch= []\n",
    "mse_list = []\n",
    "\n",
    "# initializing the trials\n",
    "TrialNumber=0\n",
    "for batch_size_trial in batch_size_list:\n",
    "    for epochs_trial in epoch_list:\n",
    "        model = Sequential()\n",
    "        # Defining the first layer of the model\n",
    "        model.add(Dense(units=5, input_shape=(5,), kernel_initializer='normal', activation='relu'))\n",
    "\n",
    "        # Defining the Second layer of the model\n",
    "        model.add(Dense(units=60, kernel_initializer='normal', activation='relu'))\n",
    "        model.add(Dense(units=60, kernel_initializer='normal', activation='relu'))\n",
    "        model.add(Dense(units=5, kernel_initializer='normal', activation='relu'))\n",
    "\n",
    "\n",
    "        # The output neuron is a single fully connected node \n",
    "        # Since we will be predicting a single number\n",
    "        model.add(Dense(1, kernel_initializer='normal', activation='linear'))\n",
    "\n",
    "        # Compiling the model\n",
    "        model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "        # Fitting the ANN to the Training set\n",
    "        model.fit(X_train, y_train ,batch_size = batch_size_trial, epochs = epochs_trial, verbose=0)\n",
    "        mse = model.evaluate(X_test, y_test, verbose=0)\n",
    "        batch_size.append(batch_size_trial)\n",
    "        epoch.append(epochs_trial)\n",
    "        mse_list.append(mse)\n",
    "\n",
    "        pred = model.predict(X_test)\n",
    "\n",
    "        y_pred=TargetVarScalerFit.inverse_transform(pred)\n",
    "        \n",
    "        # Scaling the y_test Price data back to original price scale\n",
    "        y_test_orig=TargetVarScalerFit.inverse_transform(y_test)\n",
    "\n",
    "        APE=100*(abs(y_test_orig - y_pred)/y_test_orig)\n",
    "        ape_result = 100-np.mean(APE)\n",
    "        rounded_up = math.ceil(ape_result)\n",
    "        \n",
    "        # print(\"Batch: \", batch_size_trial)\n",
    "        # print(\"epoch: \", epochs_trial)\n",
    "        # print(\"mse: \", mse)\n",
    "        # print(\"akurasi, \", ape_result)\n",
    "        # print(\"\")\n",
    "\n",
    "        SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[ 'btch ' + str(batch_size_trial) + '-' + ' epoch ' + str(epochs_trial), mse, rounded_up]], columns=['parameter', 'mse', 'akurasi']))\n",
    "\n",
    "# SearchResultsData.plot(x='parameter', y='mse', figsize=(15,4), kind='line')\n",
    "# SearchResultsData['batch_size'] = batch_size\n",
    "# SearchResultsData['epoch'] = epoch\n",
    "# SearchResultsData['mse'] = mse_list\n",
    "# print(SearchResultsData.head())\n",
    "SearchResultsData.to_excel(\"evaluasi_mse.xlsx\")\n",
    "\n",
    "# model.save(\"data/model.h5\")\n",
    "# print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 425us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qv/4r0bgwj92x98njt6rl44cc9m0000gn/T/ipykernel_97142/1506936634.py:127: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qv/4r0bgwj92x98njt6rl44cc9m0000gn/T/ipykernel_97142/1506936634.py:127: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 432us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qv/4r0bgwj92x98njt6rl44cc9m0000gn/T/ipykernel_97142/1506936634.py:127: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 421us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qv/4r0bgwj92x98njt6rl44cc9m0000gn/T/ipykernel_97142/1506936634.py:127: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 423us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qv/4r0bgwj92x98njt6rl44cc9m0000gn/T/ipykernel_97142/1506936634.py:127: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 398us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qv/4r0bgwj92x98njt6rl44cc9m0000gn/T/ipykernel_97142/1506936634.py:127: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 415us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qv/4r0bgwj92x98njt6rl44cc9m0000gn/T/ipykernel_97142/1506936634.py:127: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 440us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qv/4r0bgwj92x98njt6rl44cc9m0000gn/T/ipykernel_97142/1506936634.py:127: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 431us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qv/4r0bgwj92x98njt6rl44cc9m0000gn/T/ipykernel_97142/1506936634.py:127: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 397us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qv/4r0bgwj92x98njt6rl44cc9m0000gn/T/ipykernel_97142/1506936634.py:127: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 393us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qv/4r0bgwj92x98njt6rl44cc9m0000gn/T/ipykernel_97142/1506936634.py:127: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 393us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qv/4r0bgwj92x98njt6rl44cc9m0000gn/T/ipykernel_97142/1506936634.py:127: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 432us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qv/4r0bgwj92x98njt6rl44cc9m0000gn/T/ipykernel_97142/1506936634.py:127: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 381us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qv/4r0bgwj92x98njt6rl44cc9m0000gn/T/ipykernel_97142/1506936634.py:127: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 388us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qv/4r0bgwj92x98njt6rl44cc9m0000gn/T/ipykernel_97142/1506936634.py:127: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 365us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qv/4r0bgwj92x98njt6rl44cc9m0000gn/T/ipykernel_97142/1506936634.py:127: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 389us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qv/4r0bgwj92x98njt6rl44cc9m0000gn/T/ipykernel_97142/1506936634.py:127: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 405us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qv/4r0bgwj92x98njt6rl44cc9m0000gn/T/ipykernel_97142/1506936634.py:127: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 401us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qv/4r0bgwj92x98njt6rl44cc9m0000gn/T/ipykernel_97142/1506936634.py:127: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 402us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qv/4r0bgwj92x98njt6rl44cc9m0000gn/T/ipykernel_97142/1506936634.py:127: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 387us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qv/4r0bgwj92x98njt6rl44cc9m0000gn/T/ipykernel_97142/1506936634.py:127: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 406us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qv/4r0bgwj92x98njt6rl44cc9m0000gn/T/ipykernel_97142/1506936634.py:127: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 396us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qv/4r0bgwj92x98njt6rl44cc9m0000gn/T/ipykernel_97142/1506936634.py:127: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 408us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qv/4r0bgwj92x98njt6rl44cc9m0000gn/T/ipykernel_97142/1506936634.py:127: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 400us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qv/4r0bgwj92x98njt6rl44cc9m0000gn/T/ipykernel_97142/1506936634.py:127: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 406us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qv/4r0bgwj92x98njt6rl44cc9m0000gn/T/ipykernel_97142/1506936634.py:127: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 407us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qv/4r0bgwj92x98njt6rl44cc9m0000gn/T/ipykernel_97142/1506936634.py:127: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 410us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qv/4r0bgwj92x98njt6rl44cc9m0000gn/T/ipykernel_97142/1506936634.py:127: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 398us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qv/4r0bgwj92x98njt6rl44cc9m0000gn/T/ipykernel_97142/1506936634.py:127: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 390us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qv/4r0bgwj92x98njt6rl44cc9m0000gn/T/ipykernel_97142/1506936634.py:127: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 419us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qv/4r0bgwj92x98njt6rl44cc9m0000gn/T/ipykernel_97142/1506936634.py:127: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 399us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qv/4r0bgwj92x98njt6rl44cc9m0000gn/T/ipykernel_97142/1506936634.py:127: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 377us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qv/4r0bgwj92x98njt6rl44cc9m0000gn/T/ipykernel_97142/1506936634.py:127: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 401us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qv/4r0bgwj92x98njt6rl44cc9m0000gn/T/ipykernel_97142/1506936634.py:127: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 389us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qv/4r0bgwj92x98njt6rl44cc9m0000gn/T/ipykernel_97142/1506936634.py:127: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 393us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qv/4r0bgwj92x98njt6rl44cc9m0000gn/T/ipykernel_97142/1506936634.py:127: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 385us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qv/4r0bgwj92x98njt6rl44cc9m0000gn/T/ipykernel_97142/1506936634.py:127: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 401us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qv/4r0bgwj92x98njt6rl44cc9m0000gn/T/ipykernel_97142/1506936634.py:127: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 426us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qv/4r0bgwj92x98njt6rl44cc9m0000gn/T/ipykernel_97142/1506936634.py:127: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 401us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qv/4r0bgwj92x98njt6rl44cc9m0000gn/T/ipykernel_97142/1506936634.py:127: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 403us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qv/4r0bgwj92x98njt6rl44cc9m0000gn/T/ipykernel_97142/1506936634.py:127: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 389us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qv/4r0bgwj92x98njt6rl44cc9m0000gn/T/ipykernel_97142/1506936634.py:127: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 406us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qv/4r0bgwj92x98njt6rl44cc9m0000gn/T/ipykernel_97142/1506936634.py:127: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 398us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qv/4r0bgwj92x98njt6rl44cc9m0000gn/T/ipykernel_97142/1506936634.py:127: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 401us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qv/4r0bgwj92x98njt6rl44cc9m0000gn/T/ipykernel_97142/1506936634.py:127: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 381us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qv/4r0bgwj92x98njt6rl44cc9m0000gn/T/ipykernel_97142/1506936634.py:127: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 399us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qv/4r0bgwj92x98njt6rl44cc9m0000gn/T/ipykernel_97142/1506936634.py:127: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 399us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qv/4r0bgwj92x98njt6rl44cc9m0000gn/T/ipykernel_97142/1506936634.py:127: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n"
     ]
    }
   ],
   "source": [
    "# General data analysis/plotting\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import math\n",
    "\n",
    "# Data preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "# Neural Net modules\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "import matplotlib\n",
    "\n",
    "df = pd.read_excel(\"data_clean.xlsx\")\n",
    "df = df[['Diagnosis', 'Tindakan', 'SEX', 'UMUR_TAHUN', 'LAMA_DIRAWAT', 'INACBG', 'HARI']]\n",
    "\n",
    "df['DiagnosisCAT'] = df['Diagnosis']\n",
    "df['Diagnosis'] = df['DiagnosisCAT'].astype('category')\n",
    "df['Diagnosis'] = df['Diagnosis'].cat.reorder_categories(df['DiagnosisCAT'].unique(), ordered=True)\n",
    "df['Diagnosis'] = df['Diagnosis'].cat.codes\n",
    "\n",
    "df['TindakanCAT'] = df['Tindakan']\n",
    "df['Tindakan'] = df['TindakanCAT'].astype('category')\n",
    "df['Tindakan'] = df['Tindakan'].cat.reorder_categories(df['TindakanCAT'].unique(), ordered=True)\n",
    "df['Tindakan'] = df['Tindakan'].cat.codes\n",
    "\n",
    "df['HARICAT'] = df['HARI']\n",
    "df['HARI'] = df['HARICAT'].astype('category')\n",
    "df['HARI'] = df['HARI'].cat.reorder_categories(df['HARICAT'].unique(), ordered=True)\n",
    "df['HARI'] = df['HARI'].cat.codes\n",
    "\n",
    "severity = []\n",
    "for index, row in df.iterrows():\n",
    "    if row['INACBG'].split(\"-\")[-1] == \"I\":\n",
    "        severity.append(1)\n",
    "    elif row['INACBG'].split(\"-\")[-1] == \"II\":\n",
    "        severity.append(2)\n",
    "    else:\n",
    "        severity.append(3)\n",
    "\n",
    "df['Severity'] = severity\n",
    "\n",
    "df.dropna(axis=0, inplace=True)\n",
    "\n",
    "X = df[['Diagnosis', 'Tindakan', 'SEX', 'UMUR_TAHUN', 'Severity', 'HARI']].values\n",
    "y = df[['LAMA_DIRAWAT']].values\n",
    "\n",
    "### Sandardization of data ###\n",
    "PredictorScaler=StandardScaler()\n",
    "TargetVarScaler=StandardScaler()\n",
    "\n",
    "# # Storing the fit object for later reference\n",
    "PredictorScalerFit=PredictorScaler.fit(X)\n",
    "TargetVarScalerFit=TargetVarScaler.fit(y)\n",
    "\n",
    "# # Generating the standardized values of X and y\n",
    "X=PredictorScalerFit.transform(X)\n",
    "y=TargetVarScalerFit.transform(y)\n",
    "\n",
    "# Split the data into training and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "batch_size_list=[16, 32, 64, 128]\n",
    "epoch_list  =   [50, 100, 200, 500]\n",
    "learning_rate = [0.001, 0.01, 0.1]\n",
    "\n",
    "SearchResultsData=pd.DataFrame(columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi'])\n",
    "batch_size =[]\n",
    "epoch= []\n",
    "mse_list = []\n",
    "\n",
    "# initializing the trials\n",
    "TrialNumber=0\n",
    "for batch_size_trial in batch_size_list:\n",
    "    for epochs_trial in epoch_list:\n",
    "        for learning_trial in learning_rate:\n",
    "            model = Sequential()\n",
    "            # Defining the first layer of the model\n",
    "            model.add(Dense(units=6, input_shape=(6,), kernel_initializer='normal', activation='relu'))\n",
    "\n",
    "            # Defining the Second layer of the model\n",
    "            model.add(Dense(units=60, kernel_initializer='normal', activation='relu'))\n",
    "            model.add(Dense(units=60, kernel_initializer='normal', activation='relu'))\n",
    "            model.add(Dense(units=6, kernel_initializer='normal', activation='relu'))\n",
    "\n",
    "\n",
    "            # The output neuron is a single fully connected node \n",
    "            # Since we will be predicting a single number\n",
    "            model.add(Dense(1, kernel_initializer='normal', activation='linear'))\n",
    "            \n",
    "            optimizer = Adam(learning_rate=learning_trial)\n",
    "\n",
    "            # Compiling the model\n",
    "            model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "\n",
    "            # Fitting the ANN to the Training set\n",
    "            model.fit(X_train, y_train ,batch_size = batch_size_trial, epochs = epochs_trial, verbose=0)\n",
    "            mse = model.evaluate(X_test, y_test, verbose=0)\n",
    "            batch_size.append(batch_size_trial)\n",
    "            epoch.append(epochs_trial)\n",
    "            mse_list.append(mse)\n",
    "\n",
    "            pred = model.predict(X_test)\n",
    "\n",
    "            y_pred=TargetVarScalerFit.inverse_transform(pred)\n",
    "            \n",
    "            # Scaling the y_test Price data back to original price scale\n",
    "            y_test_orig=TargetVarScalerFit.inverse_transform(y_test)\n",
    "\n",
    "            APE=100*(abs(y_test_orig - y_pred)/y_test_orig)\n",
    "            ape_result = 100-np.mean(APE)\n",
    "            rounded_up = math.ceil(ape_result)\n",
    "            \n",
    "            # print(\"Batch: \", batch_size_trial)\n",
    "            # print(\"epoch: \", epochs_trial)\n",
    "            # print(\"learning rate: \", learning_trial)\n",
    "            # print(\"mse: \", mse)\n",
    "            # print(\"akurasi, \", ape_result)\n",
    "            # print(\"\")\n",
    "\n",
    "            SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n",
    "\n",
    "# SearchResultsData.plot(x='parameter', y='mse', figsize=(15,4), kind='line')\n",
    "# SearchResultsData['batch_size'] = batch_size\n",
    "# SearchResultsData['epoch'] = epoch\n",
    "# SearchResultsData['mse'] = mse_list\n",
    "# print(SearchResultsData.head())\n",
    "SearchResultsData.to_excel(\"evaluasi_mse_with_learning_rate.xlsx\")\n",
    "\n",
    "# model.save(\"data/model.h5\")\n",
    "# print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General data analysis/plotting\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Data preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "# Neural Net modules\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "import matplotlib\n",
    "\n",
    "df = pd.read_excel(\"data.xlsx\")\n",
    "df = df[['Diagnosis', 'Tindakan', 'SEX', 'UMUR_TAHUN', 'LAMA_DIRAWAT', 'KELAS_RAWAT']]\n",
    "\n",
    "df['DiagnosisCAT'] = df['Diagnosis']\n",
    "df['Diagnosis'] = df['DiagnosisCAT'].astype('category')\n",
    "df['Diagnosis'] = df['Diagnosis'].cat.reorder_categories(df['DiagnosisCAT'].unique(), ordered=True)\n",
    "df['Diagnosis'] = df['Diagnosis'].cat.codes\n",
    "\n",
    "df['TindakanCAT'] = df['Tindakan']\n",
    "df['Tindakan'] = df['TindakanCAT'].astype('category')\n",
    "df['Tindakan'] = df['Tindakan'].cat.reorder_categories(df['TindakanCAT'].unique(), ordered=True)\n",
    "df['Tindakan'] = df['Tindakan'].cat.codes\n",
    "\n",
    "df.dropna(axis=0, inplace=True)\n",
    "\n",
    "X = df[['Diagnosis', 'Tindakan', 'SEX', 'UMUR_TAHUN', 'KELAS_RAWAT']].values\n",
    "y = df[['LAMA_DIRAWAT']].values\n",
    "\n",
    "### Sandardization of data ###\n",
    "PredictorScaler=StandardScaler()\n",
    "TargetVarScaler=StandardScaler()\n",
    "\n",
    "# # Storing the fit object for later reference\n",
    "PredictorScalerFit=PredictorScaler.fit(X)\n",
    "TargetVarScalerFit=TargetVarScaler.fit(y)\n",
    "\n",
    "# # Generating the standardized values of X and y\n",
    "X=PredictorScalerFit.transform(X)\n",
    "y=TargetVarScalerFit.transform(y)\n",
    "\n",
    "# Split the data into training and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "batch_size_list=[100, 150, 200, 250]\n",
    "epoch_list  =   [50, 100, 200, 500]\n",
    "\n",
    "# initializing the trials\n",
    "def createModel():\n",
    "    model = Sequential()\n",
    "    # Defining the first layer of the model\n",
    "    model.add(Dense(units=5, input_shape=(5,), kernel_initializer='normal', activation='relu'))\n",
    "\n",
    "    # Defining the Second layer of the model\n",
    "    model.add(Dense(units=60, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(units=60, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(units=5, kernel_initializer='normal', activation='relu'))\n",
    "\n",
    "\n",
    "    # The output neuron is a single fully connected node \n",
    "    # Since we will be predicting a single number\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='linear'))\n",
    "\n",
    "    # Compiling the model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "    return model\n",
    "\n",
    "model = KerasRegressor(model=createModel, verbose=0)\n",
    "\n",
    "param_grid = dict(batch_size=batch_size_list, epochs=epoch_list)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# summarize results\n",
    "grid_pred = grid_result.predict(X_test)\n",
    "\n",
    "gg = []\n",
    "for i in grid_pred:\n",
    "    gg.append(i)\n",
    "\n",
    "y_valid = y_test.copy()\n",
    "\n",
    "gf = pd.DataFrame(data=gg)\n",
    "# gf = gf.set_index(y_valid.index)\n",
    "gf.rename(columns={0: \"predicted\"}, inplace=True)\n",
    "df321 = pd.DataFrame(data=[[y_valid, gf]])\n",
    "df321.columns = [\"Y_true\", \"Y_pred\"]\n",
    "\n",
    "df321[\"Squared Error\"] = (df321[\"Y_true\"] - df321[\"Y_pred\"] )**2\n",
    "print(df321['Squared Error'].head())\n",
    "\n",
    "\n",
    "# print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "# means = grid_result.cv_results_['mean_test_score']\n",
    "# stds = grid_result.cv_results_['std_test_score']\n",
    "# params = grid_result.cv_results_['params']\n",
    "# for mean, stdev, param in zip(means, stds, params):\n",
    "#     print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "# from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_excel(\"data.xlsx\")\n",
    "df = df[['Diagnosis', 'Tindakan', 'SEX', 'UMUR_TAHUN', 'LAMA_DIRAWAT', 'KELAS_RAWAT']]\n",
    "\n",
    "df['DiagnosisCAT'] = df['Diagnosis']\n",
    "df['Diagnosis'] = df['DiagnosisCAT'].astype('category')\n",
    "df['Diagnosis'] = df['Diagnosis'].cat.reorder_categories(df['DiagnosisCAT'].unique(), ordered=True)\n",
    "df['Diagnosis'] = df['Diagnosis'].cat.codes\n",
    "\n",
    "df['TindakanCAT'] = df['Tindakan']\n",
    "df['Tindakan'] = df['TindakanCAT'].astype('category')\n",
    "df['Tindakan'] = df['Tindakan'].cat.reorder_categories(df['TindakanCAT'].unique(), ordered=True)\n",
    "df['Tindakan'] = df['Tindakan'].cat.codes\n",
    "\n",
    "df.dropna(axis=0, inplace=True)\n",
    "\n",
    "X = df[['Diagnosis', 'Tindakan', 'SEX', 'UMUR_TAHUN', 'KELAS_RAWAT']].values\n",
    "y = df[['LAMA_DIRAWAT']].values\n",
    "\n",
    "### Sandardization of data ###\n",
    "PredictorScaler=StandardScaler()\n",
    "TargetVarScaler=StandardScaler()\n",
    "\n",
    "# Storing the fit object for later reference\n",
    "PredictorScalerFit=PredictorScaler.fit(X)\n",
    "TargetVarScalerFit=TargetVarScaler.fit(y)\n",
    "\n",
    "# # Generating the standardized values of X and y\n",
    "X=PredictorScalerFit.transform(X)\n",
    "y=TargetVarScalerFit.transform(y)\n",
    "\n",
    "# Split the data into training and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "batch_size_list=[100, 150, 200, 250]\n",
    "epoch_list  =   [50, 100, 200, 500]\n",
    "\n",
    "SearchResultsData=pd.DataFrame(columns=['parameter', 'mse', 'akurasi'])\n",
    "\n",
    "# Function to create the model\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    # Defining the first layer of the model\n",
    "    model.add(Dense(units=5, input_shape=(5,), kernel_initializer='normal', activation='relu'))\n",
    "\n",
    "    # Defining the Second layer of the model\n",
    "    model.add(Dense(units=60, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(units=60, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(units=5, kernel_initializer='normal', activation='relu'))\n",
    "\n",
    "\n",
    "    # The output neuron is a single fully connected node \n",
    "    # Since we will be predicting a single number\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='linear'))\n",
    "\n",
    "    # Compiling the model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "\n",
    "model = KerasRegressor(model=create_model, verbose=0)\n",
    "\n",
    "# Define the hyperparameters grid\n",
    "param_grid = {'batch_size': batch_size_list,\n",
    "              'epochs': epoch_list}\n",
    "\n",
    "# Perform grid search\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# Get the results of grid search\n",
    "results = grid_result.cv_results_\n",
    "\n",
    "# Print MSE for each parameter combination\n",
    "for mean_score, params in zip(results[\"mean_test_score\"], results[\"params\"]):\n",
    "    model = KerasRegressor(model=create_model, verbose=0, **params)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Scaling the predicted Price data back to original price scale\n",
    "    y_pred_origin=TargetVarScalerFit.inverse_transform(y_pred)\n",
    "    \n",
    "    # Scaling the y_test Price data back to original price scale\n",
    "    y_test_origin=TargetVarScalerFit.inverse_transform(y_test)\n",
    "    \n",
    "    mse = mean_squared_error(y_pred= y_pred, y_true= y_test)\n",
    "\n",
    "    APE=100*(abs(y_test_origin - y_pred_origin)/y_test_origin)\n",
    "    ape_result = 100-np.mean(APE)\n",
    "    \n",
    "    # SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[ 'batch ' + str(params['batch_size']) + '-' + ' epoch ' + str(params['epochs']), mse, ape_result]], columns=['parameter', 'mse', 'akurasi']))\n",
    "    \n",
    "    print(\"Parameters: \", params)\n",
    "    print(\"Mean Squared Error: \", mse)\n",
    "    print(\"akurasi: \", ape_result)\n",
    "    print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rs_api",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
