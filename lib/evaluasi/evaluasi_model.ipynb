{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 4ms/step\n",
      "Batch:  16\n",
      "epoch:  50\n",
      "mse:  0.059133272618055344\n",
      "akurasi,  92.99701687037533\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muham\\AppData\\Local\\Temp\\ipykernel_8952\\4221227721.py:116: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[ 'btch ' + str(batch_size_trial) + '-' + ' epoch ' + str(epochs_trial), mse, rounded_up]], columns=['parameter', 'mse', 'akurasi']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 3ms/step\n",
      "Batch:  16\n",
      "epoch:  100\n",
      "mse:  0.01472601667046547\n",
      "akurasi,  96.75045807922194\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muham\\AppData\\Local\\Temp\\ipykernel_8952\\4221227721.py:116: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[ 'btch ' + str(batch_size_trial) + '-' + ' epoch ' + str(epochs_trial), mse, rounded_up]], columns=['parameter', 'mse', 'akurasi']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 4ms/step\n",
      "Batch:  16\n",
      "epoch:  200\n",
      "mse:  0.01628158427774906\n",
      "akurasi,  96.80299919517316\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muham\\AppData\\Local\\Temp\\ipykernel_8952\\4221227721.py:116: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[ 'btch ' + str(batch_size_trial) + '-' + ' epoch ' + str(epochs_trial), mse, rounded_up]], columns=['parameter', 'mse', 'akurasi']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 0s/step\n",
      "Batch:  16\n",
      "epoch:  500\n",
      "mse:  0.058693066239356995\n",
      "akurasi,  96.45705121188415\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muham\\AppData\\Local\\Temp\\ipykernel_8952\\4221227721.py:116: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[ 'btch ' + str(batch_size_trial) + '-' + ' epoch ' + str(epochs_trial), mse, rounded_up]], columns=['parameter', 'mse', 'akurasi']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x0000022526B9FEB0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000022528EDCC10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "Batch:  32\n",
      "epoch:  50\n",
      "mse:  0.08441396057605743\n",
      "akurasi,  91.37218823260139\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muham\\AppData\\Local\\Temp\\ipykernel_8952\\4221227721.py:116: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[ 'btch ' + str(batch_size_trial) + '-' + ' epoch ' + str(epochs_trial), mse, rounded_up]], columns=['parameter', 'mse', 'akurasi']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x0000022528EDD2D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000022528EDE950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 0s/step\n",
      "Batch:  32\n",
      "epoch:  100\n",
      "mse:  0.0375090017914772\n",
      "akurasi,  95.04221483087892\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muham\\AppData\\Local\\Temp\\ipykernel_8952\\4221227721.py:116: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[ 'btch ' + str(batch_size_trial) + '-' + ' epoch ' + str(epochs_trial), mse, rounded_up]], columns=['parameter', 'mse', 'akurasi']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 4ms/step\n",
      "Batch:  32\n",
      "epoch:  200\n",
      "mse:  0.13894277811050415\n",
      "akurasi,  93.5678001858159\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muham\\AppData\\Local\\Temp\\ipykernel_8952\\4221227721.py:116: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[ 'btch ' + str(batch_size_trial) + '-' + ' epoch ' + str(epochs_trial), mse, rounded_up]], columns=['parameter', 'mse', 'akurasi']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 4ms/step\n",
      "Batch:  32\n",
      "epoch:  500\n",
      "mse:  0.03471282869577408\n",
      "akurasi,  95.44835441200344\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muham\\AppData\\Local\\Temp\\ipykernel_8952\\4221227721.py:116: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[ 'btch ' + str(batch_size_trial) + '-' + ' epoch ' + str(epochs_trial), mse, rounded_up]], columns=['parameter', 'mse', 'akurasi']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 3ms/step\n",
      "Batch:  64\n",
      "epoch:  50\n",
      "mse:  0.5146306157112122\n",
      "akurasi,  84.77957368599445\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muham\\AppData\\Local\\Temp\\ipykernel_8952\\4221227721.py:116: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[ 'btch ' + str(batch_size_trial) + '-' + ' epoch ' + str(epochs_trial), mse, rounded_up]], columns=['parameter', 'mse', 'akurasi']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 4ms/step\n",
      "Batch:  64\n",
      "epoch:  100\n",
      "mse:  0.185575470328331\n",
      "akurasi,  81.86405191766312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muham\\AppData\\Local\\Temp\\ipykernel_8952\\4221227721.py:116: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[ 'btch ' + str(batch_size_trial) + '-' + ' epoch ' + str(epochs_trial), mse, rounded_up]], columns=['parameter', 'mse', 'akurasi']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 0s/step\n",
      "Batch:  64\n",
      "epoch:  200\n",
      "mse:  0.06657492369413376\n",
      "akurasi,  93.77646687045318\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muham\\AppData\\Local\\Temp\\ipykernel_8952\\4221227721.py:116: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[ 'btch ' + str(batch_size_trial) + '-' + ' epoch ' + str(epochs_trial), mse, rounded_up]], columns=['parameter', 'mse', 'akurasi']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 0s/step\n",
      "Batch:  64\n",
      "epoch:  500\n",
      "mse:  0.013656605035066605\n",
      "akurasi,  98.031332231407\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muham\\AppData\\Local\\Temp\\ipykernel_8952\\4221227721.py:116: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[ 'btch ' + str(batch_size_trial) + '-' + ' epoch ' + str(epochs_trial), mse, rounded_up]], columns=['parameter', 'mse', 'akurasi']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 4ms/step\n",
      "Batch:  128\n",
      "epoch:  50\n",
      "mse:  0.5703044533729553\n",
      "akurasi,  83.1698058719042\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muham\\AppData\\Local\\Temp\\ipykernel_8952\\4221227721.py:116: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[ 'btch ' + str(batch_size_trial) + '-' + ' epoch ' + str(epochs_trial), mse, rounded_up]], columns=['parameter', 'mse', 'akurasi']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 3ms/step\n",
      "Batch:  128\n",
      "epoch:  100\n",
      "mse:  0.46332502365112305\n",
      "akurasi,  87.1093144519495\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muham\\AppData\\Local\\Temp\\ipykernel_8952\\4221227721.py:116: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[ 'btch ' + str(batch_size_trial) + '-' + ' epoch ' + str(epochs_trial), mse, rounded_up]], columns=['parameter', 'mse', 'akurasi']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 5ms/step\n",
      "Batch:  128\n",
      "epoch:  200\n",
      "mse:  0.05646054446697235\n",
      "akurasi,  93.13425343782929\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muham\\AppData\\Local\\Temp\\ipykernel_8952\\4221227721.py:116: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[ 'btch ' + str(batch_size_trial) + '-' + ' epoch ' + str(epochs_trial), mse, rounded_up]], columns=['parameter', 'mse', 'akurasi']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 5ms/step\n",
      "Batch:  128\n",
      "epoch:  500\n",
      "mse:  0.0187135748565197\n",
      "akurasi,  97.65335359022139\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muham\\AppData\\Local\\Temp\\ipykernel_8952\\4221227721.py:116: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[ 'btch ' + str(batch_size_trial) + '-' + ' epoch ' + str(epochs_trial), mse, rounded_up]], columns=['parameter', 'mse', 'akurasi']))\n"
     ]
    }
   ],
   "source": [
    "# General data analysis/plotting\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import math\n",
    "\n",
    "# Data preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "# Neural Net modules\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "import matplotlib\n",
    "\n",
    "df = pd.read_excel(\"data.xlsx\")\n",
    "df = df[['Diagnosis', 'Tindakan', 'SEX', 'UMUR_TAHUN', 'LAMA_DIRAWAT', 'INACBG']]\n",
    "\n",
    "df['DiagnosisCAT'] = df['Diagnosis']\n",
    "df['Diagnosis'] = df['DiagnosisCAT'].astype('category')\n",
    "df['Diagnosis'] = df['Diagnosis'].cat.reorder_categories(df['DiagnosisCAT'].unique(), ordered=True)\n",
    "df['Diagnosis'] = df['Diagnosis'].cat.codes\n",
    "\n",
    "df['TindakanCAT'] = df['Tindakan']\n",
    "df['Tindakan'] = df['TindakanCAT'].astype('category')\n",
    "df['Tindakan'] = df['Tindakan'].cat.reorder_categories(df['TindakanCAT'].unique(), ordered=True)\n",
    "df['Tindakan'] = df['Tindakan'].cat.codes\n",
    "\n",
    "severity = []\n",
    "for index, row in df.iterrows():\n",
    "    if row['INACBG'].split(\"-\")[-1] == \"I\":\n",
    "        severity.append(1)\n",
    "    elif row['INACBG'].split(\"-\")[-1] == \"II\":\n",
    "        severity.append(2)\n",
    "    else:\n",
    "        severity.append(3)\n",
    "\n",
    "df['Severity'] = severity\n",
    "\n",
    "df.dropna(axis=0, inplace=True)\n",
    "\n",
    "X = df[['Diagnosis', 'Tindakan', 'SEX', 'UMUR_TAHUN', 'Severity']].values\n",
    "y = df[['LAMA_DIRAWAT']].values\n",
    "\n",
    "### Sandardization of data ###\n",
    "PredictorScaler=StandardScaler()\n",
    "TargetVarScaler=StandardScaler()\n",
    "\n",
    "# # Storing the fit object for later reference\n",
    "PredictorScalerFit=PredictorScaler.fit(X)\n",
    "TargetVarScalerFit=TargetVarScaler.fit(y)\n",
    "\n",
    "# # Generating the standardized values of X and y\n",
    "X=PredictorScalerFit.transform(X)\n",
    "y=TargetVarScalerFit.transform(y)\n",
    "\n",
    "# Split the data into training and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "batch_size_list=[16, 32, 64, 128]\n",
    "epoch_list  =   [50, 100, 200, 500]\n",
    "\n",
    "SearchResultsData=pd.DataFrame(columns=['parameter', 'mse', 'akurasi'])\n",
    "batch_size =[]\n",
    "epoch= []\n",
    "mse_list = []\n",
    "\n",
    "# initializing the trials\n",
    "TrialNumber=0\n",
    "for batch_size_trial in batch_size_list:\n",
    "    for epochs_trial in epoch_list:\n",
    "        model = Sequential()\n",
    "        # Defining the first layer of the model\n",
    "        model.add(Dense(units=5, input_shape=(5,), kernel_initializer='normal', activation='relu'))\n",
    "\n",
    "        # Defining the Second layer of the model\n",
    "        model.add(Dense(units=60, kernel_initializer='normal', activation='relu'))\n",
    "        model.add(Dense(units=60, kernel_initializer='normal', activation='relu'))\n",
    "        model.add(Dense(units=5, kernel_initializer='normal', activation='relu'))\n",
    "\n",
    "\n",
    "        # The output neuron is a single fully connected node \n",
    "        # Since we will be predicting a single number\n",
    "        model.add(Dense(1, kernel_initializer='normal', activation='linear'))\n",
    "\n",
    "        # Compiling the model\n",
    "        model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "        # Fitting the ANN to the Training set\n",
    "        model.fit(X_train, y_train ,batch_size = batch_size_trial, epochs = epochs_trial, verbose=0)\n",
    "        mse = model.evaluate(X_test, y_test, verbose=0)\n",
    "        batch_size.append(batch_size_trial)\n",
    "        epoch.append(epochs_trial)\n",
    "        mse_list.append(mse)\n",
    "\n",
    "        pred = model.predict(X_test)\n",
    "\n",
    "        y_pred=TargetVarScalerFit.inverse_transform(pred)\n",
    "        \n",
    "        # Scaling the y_test Price data back to original price scale\n",
    "        y_test_orig=TargetVarScalerFit.inverse_transform(y_test)\n",
    "\n",
    "        APE=100*(abs(y_test_orig - y_pred)/y_test_orig)\n",
    "        ape_result = 100-np.mean(APE)\n",
    "        rounded_up = math.ceil(ape_result)\n",
    "        \n",
    "        print(\"Batch: \", batch_size_trial)\n",
    "        print(\"epoch: \", epochs_trial)\n",
    "        print(\"mse: \", mse)\n",
    "        print(\"akurasi, \", ape_result)\n",
    "        print(\"\")\n",
    "\n",
    "        SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[ 'btch ' + str(batch_size_trial) + '-' + ' epoch ' + str(epochs_trial), mse, rounded_up]], columns=['parameter', 'mse', 'akurasi']))\n",
    "\n",
    "# SearchResultsData.plot(x='parameter', y='mse', figsize=(15,4), kind='line')\n",
    "# SearchResultsData['batch_size'] = batch_size\n",
    "# SearchResultsData['epoch'] = epoch\n",
    "# SearchResultsData['mse'] = mse_list\n",
    "# print(SearchResultsData.head())\n",
    "SearchResultsData.to_excel(\"evaluasi_mse.xlsx\")\n",
    "\n",
    "# model.save(\"data/model.h5\")\n",
    "# print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 5ms/step\n",
      "Batch:  16\n",
      "epoch:  50\n",
      "learning rate:  0.001\n",
      "mse:  0.11716139316558838\n",
      "akurasi,  87.33269303468475\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muham\\AppData\\Local\\Temp\\ipykernel_8952\\4276221582.py:122: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 0s/step\n",
      "Batch:  16\n",
      "epoch:  50\n",
      "learning rate:  0.01\n",
      "mse:  0.03889009729027748\n",
      "akurasi,  95.20613592498498\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muham\\AppData\\Local\\Temp\\ipykernel_8952\\4276221582.py:122: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 4ms/step\n",
      "Batch:  16\n",
      "epoch:  50\n",
      "learning rate:  0.1\n",
      "mse:  0.9208301901817322\n",
      "akurasi,  63.226355389417584\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muham\\AppData\\Local\\Temp\\ipykernel_8952\\4276221582.py:122: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 4ms/step\n",
      "Batch:  16\n",
      "epoch:  100\n",
      "learning rate:  0.001\n",
      "mse:  0.06630276143550873\n",
      "akurasi,  91.61209183634139\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muham\\AppData\\Local\\Temp\\ipykernel_8952\\4276221582.py:122: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 4ms/step\n",
      "Batch:  16\n",
      "epoch:  100\n",
      "learning rate:  0.01\n",
      "mse:  0.04098393768072128\n",
      "akurasi,  96.42355816112376\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muham\\AppData\\Local\\Temp\\ipykernel_8952\\4276221582.py:122: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 3ms/step\n",
      "Batch:  16\n",
      "epoch:  100\n",
      "learning rate:  0.1\n",
      "mse:  0.2516736090183258\n",
      "akurasi,  84.36079641197551\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muham\\AppData\\Local\\Temp\\ipykernel_8952\\4276221582.py:122: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 4ms/step\n",
      "Batch:  16\n",
      "epoch:  200\n",
      "learning rate:  0.001\n",
      "mse:  0.04435637965798378\n",
      "akurasi,  95.14768141187\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muham\\AppData\\Local\\Temp\\ipykernel_8952\\4276221582.py:122: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 3ms/step\n",
      "Batch:  16\n",
      "epoch:  200\n",
      "learning rate:  0.01\n",
      "mse:  0.015988755971193314\n",
      "akurasi,  97.81934110198397\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muham\\AppData\\Local\\Temp\\ipykernel_8952\\4276221582.py:122: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 4ms/step\n",
      "Batch:  16\n",
      "epoch:  200\n",
      "learning rate:  0.1\n",
      "mse:  0.920094907283783\n",
      "akurasi,  63.34298079449033\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muham\\AppData\\Local\\Temp\\ipykernel_8952\\4276221582.py:122: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 4ms/step\n",
      "Batch:  16\n",
      "epoch:  500\n",
      "learning rate:  0.001\n",
      "mse:  0.06818243116140366\n",
      "akurasi,  94.81653951862233\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muham\\AppData\\Local\\Temp\\ipykernel_8952\\4276221582.py:122: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 0s/step\n",
      "Batch:  16\n",
      "epoch:  500\n",
      "learning rate:  0.01\n",
      "mse:  0.023132994771003723\n",
      "akurasi,  98.02181996045557\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muham\\AppData\\Local\\Temp\\ipykernel_8952\\4276221582.py:122: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 0s/step\n",
      "Batch:  16\n",
      "epoch:  500\n",
      "learning rate:  0.1\n",
      "mse:  0.9237791895866394\n",
      "akurasi,  65.51997595152947\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muham\\AppData\\Local\\Temp\\ipykernel_8952\\4276221582.py:122: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 0s/step\n",
      "Batch:  32\n",
      "epoch:  50\n",
      "learning rate:  0.001\n",
      "mse:  0.06503895670175552\n",
      "akurasi,  92.48817214457695\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muham\\AppData\\Local\\Temp\\ipykernel_8952\\4276221582.py:122: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 0s/step\n",
      "Batch:  32\n",
      "epoch:  50\n",
      "learning rate:  0.01\n",
      "mse:  0.05445055663585663\n",
      "akurasi,  94.17086859467665\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muham\\AppData\\Local\\Temp\\ipykernel_8952\\4276221582.py:122: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 0s/step\n",
      "Batch:  32\n",
      "epoch:  50\n",
      "learning rate:  0.1\n",
      "mse:  0.07569453120231628\n",
      "akurasi,  93.39350312396331\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muham\\AppData\\Local\\Temp\\ipykernel_8952\\4276221582.py:122: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 0s/step\n",
      "Batch:  32\n",
      "epoch:  100\n",
      "learning rate:  0.001\n",
      "mse:  0.057768575847148895\n",
      "akurasi,  93.31608924347563\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muham\\AppData\\Local\\Temp\\ipykernel_8952\\4276221582.py:122: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 0s/step\n",
      "Batch:  32\n",
      "epoch:  100\n",
      "learning rate:  0.01\n",
      "mse:  0.07399727404117584\n",
      "akurasi,  95.21820383283483\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muham\\AppData\\Local\\Temp\\ipykernel_8952\\4276221582.py:122: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 8ms/step\n",
      "Batch:  32\n",
      "epoch:  100\n",
      "learning rate:  0.1\n",
      "mse:  0.9211628437042236\n",
      "akurasi,  63.17801914216808\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muham\\AppData\\Local\\Temp\\ipykernel_8952\\4276221582.py:122: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 0s/step\n",
      "Batch:  32\n",
      "epoch:  200\n",
      "learning rate:  0.001\n",
      "mse:  0.029027726501226425\n",
      "akurasi,  94.67422525068879\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muham\\AppData\\Local\\Temp\\ipykernel_8952\\4276221582.py:122: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 8ms/step\n",
      "Batch:  32\n",
      "epoch:  200\n",
      "learning rate:  0.01\n",
      "mse:  0.044615522027015686\n",
      "akurasi,  95.00412619702132\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muham\\AppData\\Local\\Temp\\ipykernel_8952\\4276221582.py:122: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 0s/step\n",
      "Batch:  32\n",
      "epoch:  200\n",
      "learning rate:  0.1\n",
      "mse:  0.06920980662107468\n",
      "akurasi,  92.25501963830212\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muham\\AppData\\Local\\Temp\\ipykernel_8952\\4276221582.py:122: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 0s/step\n",
      "Batch:  32\n",
      "epoch:  500\n",
      "learning rate:  0.001\n",
      "mse:  0.01792849227786064\n",
      "akurasi,  97.66144115615774\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muham\\AppData\\Local\\Temp\\ipykernel_8952\\4276221582.py:122: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 8ms/step\n",
      "Batch:  32\n",
      "epoch:  500\n",
      "learning rate:  0.01\n",
      "mse:  0.018359633162617683\n",
      "akurasi,  97.03045162636442\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muham\\AppData\\Local\\Temp\\ipykernel_8952\\4276221582.py:122: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 8ms/step\n",
      "Batch:  32\n",
      "epoch:  500\n",
      "learning rate:  0.1\n",
      "mse:  0.15258149802684784\n",
      "akurasi,  87.66926756449115\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muham\\AppData\\Local\\Temp\\ipykernel_8952\\4276221582.py:122: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 0s/step\n",
      "Batch:  64\n",
      "epoch:  50\n",
      "learning rate:  0.001\n",
      "mse:  0.06789562106132507\n",
      "akurasi,  91.08790311144678\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muham\\AppData\\Local\\Temp\\ipykernel_8952\\4276221582.py:122: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 0s/step\n",
      "Batch:  64\n",
      "epoch:  50\n",
      "learning rate:  0.01\n",
      "mse:  0.11548590660095215\n",
      "akurasi,  93.50320571180298\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muham\\AppData\\Local\\Temp\\ipykernel_8952\\4276221582.py:122: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 0s/step\n",
      "Batch:  64\n",
      "epoch:  50\n",
      "learning rate:  0.1\n",
      "mse:  0.9182667136192322\n",
      "akurasi,  64.62593467620314\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muham\\AppData\\Local\\Temp\\ipykernel_8952\\4276221582.py:122: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 0s/step\n",
      "Batch:  64\n",
      "epoch:  100\n",
      "learning rate:  0.001\n",
      "mse:  0.3970937728881836\n",
      "akurasi,  88.36013226492275\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muham\\AppData\\Local\\Temp\\ipykernel_8952\\4276221582.py:122: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 0s/step\n",
      "Batch:  64\n",
      "epoch:  100\n",
      "learning rate:  0.01\n",
      "mse:  0.07445663213729858\n",
      "akurasi,  95.0324735215063\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muham\\AppData\\Local\\Temp\\ipykernel_8952\\4276221582.py:122: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 0s/step\n",
      "Batch:  64\n",
      "epoch:  100\n",
      "learning rate:  0.1\n",
      "mse:  0.01870991848409176\n",
      "akurasi,  96.4534162237932\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muham\\AppData\\Local\\Temp\\ipykernel_8952\\4276221582.py:122: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 0s/step\n",
      "Batch:  64\n",
      "epoch:  200\n",
      "learning rate:  0.001\n",
      "mse:  0.08728542923927307\n",
      "akurasi,  88.44203768512158\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muham\\AppData\\Local\\Temp\\ipykernel_8952\\4276221582.py:122: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 0s/step\n",
      "Batch:  64\n",
      "epoch:  200\n",
      "learning rate:  0.01\n",
      "mse:  0.021766986697912216\n",
      "akurasi,  96.86550029650682\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muham\\AppData\\Local\\Temp\\ipykernel_8952\\4276221582.py:122: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 0s/step\n",
      "Batch:  64\n",
      "epoch:  200\n",
      "learning rate:  0.1\n",
      "mse:  0.049322210252285004\n",
      "akurasi,  94.02946394037814\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muham\\AppData\\Local\\Temp\\ipykernel_8952\\4276221582.py:122: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 0s/step\n",
      "Batch:  64\n",
      "epoch:  500\n",
      "learning rate:  0.001\n",
      "mse:  0.01241425983607769\n",
      "akurasi,  97.62319116931572\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muham\\AppData\\Local\\Temp\\ipykernel_8952\\4276221582.py:122: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 8ms/step\n",
      "Batch:  64\n",
      "epoch:  500\n",
      "learning rate:  0.01\n",
      "mse:  0.05261205509305\n",
      "akurasi,  95.24489904911698\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muham\\AppData\\Local\\Temp\\ipykernel_8952\\4276221582.py:122: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 0s/step\n",
      "Batch:  64\n",
      "epoch:  500\n",
      "learning rate:  0.1\n",
      "mse:  0.07715897262096405\n",
      "akurasi,  93.31784178306798\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muham\\AppData\\Local\\Temp\\ipykernel_8952\\4276221582.py:122: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 8ms/step\n",
      "Batch:  128\n",
      "epoch:  50\n",
      "learning rate:  0.001\n",
      "mse:  0.32747527956962585\n",
      "akurasi,  75.52597812559239\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muham\\AppData\\Local\\Temp\\ipykernel_8952\\4276221582.py:122: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 0s/step\n",
      "Batch:  128\n",
      "epoch:  50\n",
      "learning rate:  0.01\n",
      "mse:  0.07862056791782379\n",
      "akurasi,  92.27134519246349\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muham\\AppData\\Local\\Temp\\ipykernel_8952\\4276221582.py:122: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 8ms/step\n",
      "Batch:  128\n",
      "epoch:  50\n",
      "learning rate:  0.1\n",
      "mse:  0.04456756263971329\n",
      "akurasi,  91.21530227526767\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muham\\AppData\\Local\\Temp\\ipykernel_8952\\4276221582.py:122: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 0s/step\n",
      "Batch:  128\n",
      "epoch:  100\n",
      "learning rate:  0.001\n",
      "mse:  0.455260694026947\n",
      "akurasi,  87.08600857284793\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muham\\AppData\\Local\\Temp\\ipykernel_8952\\4276221582.py:122: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 0s/step\n",
      "Batch:  128\n",
      "epoch:  100\n",
      "learning rate:  0.01\n",
      "mse:  0.04659734293818474\n",
      "akurasi,  95.45973930478631\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muham\\AppData\\Local\\Temp\\ipykernel_8952\\4276221582.py:122: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 0s/step\n",
      "Batch:  128\n",
      "epoch:  100\n",
      "learning rate:  0.1\n",
      "mse:  0.9269326329231262\n",
      "akurasi,  65.81316789717596\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muham\\AppData\\Local\\Temp\\ipykernel_8952\\4276221582.py:122: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 0s/step\n",
      "Batch:  128\n",
      "epoch:  200\n",
      "learning rate:  0.001\n",
      "mse:  0.04650402069091797\n",
      "akurasi,  94.60149337470541\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muham\\AppData\\Local\\Temp\\ipykernel_8952\\4276221582.py:122: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 8ms/step\n",
      "Batch:  128\n",
      "epoch:  200\n",
      "learning rate:  0.01\n",
      "mse:  0.02499852515757084\n",
      "akurasi,  96.92646915981531\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muham\\AppData\\Local\\Temp\\ipykernel_8952\\4276221582.py:122: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 0s/step\n",
      "Batch:  128\n",
      "epoch:  200\n",
      "learning rate:  0.1\n",
      "mse:  0.0702531635761261\n",
      "akurasi,  93.95981396880691\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muham\\AppData\\Local\\Temp\\ipykernel_8952\\4276221582.py:122: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 8ms/step\n",
      "Batch:  128\n",
      "epoch:  500\n",
      "learning rate:  0.001\n",
      "mse:  0.9218201041221619\n",
      "akurasi,  65.288893641838\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muham\\AppData\\Local\\Temp\\ipykernel_8952\\4276221582.py:122: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 0s/step\n",
      "Batch:  128\n",
      "epoch:  500\n",
      "learning rate:  0.01\n",
      "mse:  0.020933235064148903\n",
      "akurasi,  96.99912152019701\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muham\\AppData\\Local\\Temp\\ipykernel_8952\\4276221582.py:122: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 0s/step\n",
      "Batch:  128\n",
      "epoch:  500\n",
      "learning rate:  0.1\n",
      "mse:  0.9228876829147339\n",
      "akurasi,  65.42021478165682\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muham\\AppData\\Local\\Temp\\ipykernel_8952\\4276221582.py:122: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n"
     ]
    }
   ],
   "source": [
    "# General data analysis/plotting\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import math\n",
    "\n",
    "# Data preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "# Neural Net modules\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "import matplotlib\n",
    "\n",
    "df = pd.read_excel(\"data.xlsx\")\n",
    "df = df[['Diagnosis', 'Tindakan', 'SEX', 'UMUR_TAHUN', 'LAMA_DIRAWAT', 'INACBG']]\n",
    "\n",
    "df['DiagnosisCAT'] = df['Diagnosis']\n",
    "df['Diagnosis'] = df['DiagnosisCAT'].astype('category')\n",
    "df['Diagnosis'] = df['Diagnosis'].cat.reorder_categories(df['DiagnosisCAT'].unique(), ordered=True)\n",
    "df['Diagnosis'] = df['Diagnosis'].cat.codes\n",
    "\n",
    "df['TindakanCAT'] = df['Tindakan']\n",
    "df['Tindakan'] = df['TindakanCAT'].astype('category')\n",
    "df['Tindakan'] = df['Tindakan'].cat.reorder_categories(df['TindakanCAT'].unique(), ordered=True)\n",
    "df['Tindakan'] = df['Tindakan'].cat.codes\n",
    "\n",
    "severity = []\n",
    "for index, row in df.iterrows():\n",
    "    if row['INACBG'].split(\"-\")[-1] == \"I\":\n",
    "        severity.append(1)\n",
    "    elif row['INACBG'].split(\"-\")[-1] == \"II\":\n",
    "        severity.append(2)\n",
    "    else:\n",
    "        severity.append(3)\n",
    "\n",
    "df['Severity'] = severity\n",
    "\n",
    "df.dropna(axis=0, inplace=True)\n",
    "\n",
    "X = df[['Diagnosis', 'Tindakan', 'SEX', 'UMUR_TAHUN', 'Severity']].values\n",
    "y = df[['LAMA_DIRAWAT']].values\n",
    "\n",
    "### Sandardization of data ###\n",
    "PredictorScaler=StandardScaler()\n",
    "TargetVarScaler=StandardScaler()\n",
    "\n",
    "# # Storing the fit object for later reference\n",
    "PredictorScalerFit=PredictorScaler.fit(X)\n",
    "TargetVarScalerFit=TargetVarScaler.fit(y)\n",
    "\n",
    "# # Generating the standardized values of X and y\n",
    "X=PredictorScalerFit.transform(X)\n",
    "y=TargetVarScalerFit.transform(y)\n",
    "\n",
    "# Split the data into training and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "batch_size_list=[16, 32, 64, 128]\n",
    "epoch_list  =   [50, 100, 200, 500]\n",
    "learning_rate = [0.001, 0.01, 0.1]\n",
    "\n",
    "SearchResultsData=pd.DataFrame(columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi'])\n",
    "batch_size =[]\n",
    "epoch= []\n",
    "mse_list = []\n",
    "\n",
    "# initializing the trials\n",
    "TrialNumber=0\n",
    "for batch_size_trial in batch_size_list:\n",
    "    for epochs_trial in epoch_list:\n",
    "        for learning_trial in learning_rate:\n",
    "            model = Sequential()\n",
    "            # Defining the first layer of the model\n",
    "            model.add(Dense(units=5, input_shape=(5,), kernel_initializer='normal', activation='relu'))\n",
    "\n",
    "            # Defining the Second layer of the model\n",
    "            model.add(Dense(units=60, kernel_initializer='normal', activation='relu'))\n",
    "            model.add(Dense(units=60, kernel_initializer='normal', activation='relu'))\n",
    "            model.add(Dense(units=5, kernel_initializer='normal', activation='relu'))\n",
    "\n",
    "\n",
    "            # The output neuron is a single fully connected node \n",
    "            # Since we will be predicting a single number\n",
    "            model.add(Dense(1, kernel_initializer='normal', activation='linear'))\n",
    "            \n",
    "            optimizer = Adam(learning_rate=learning_trial)\n",
    "\n",
    "            # Compiling the model\n",
    "            model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "\n",
    "            # Fitting the ANN to the Training set\n",
    "            model.fit(X_train, y_train ,batch_size = batch_size_trial, epochs = epochs_trial, verbose=0)\n",
    "            mse = model.evaluate(X_test, y_test, verbose=0)\n",
    "            batch_size.append(batch_size_trial)\n",
    "            epoch.append(epochs_trial)\n",
    "            mse_list.append(mse)\n",
    "\n",
    "            pred = model.predict(X_test)\n",
    "\n",
    "            y_pred=TargetVarScalerFit.inverse_transform(pred)\n",
    "            \n",
    "            # Scaling the y_test Price data back to original price scale\n",
    "            y_test_orig=TargetVarScalerFit.inverse_transform(y_test)\n",
    "\n",
    "            APE=100*(abs(y_test_orig - y_pred)/y_test_orig)\n",
    "            ape_result = 100-np.mean(APE)\n",
    "            rounded_up = math.ceil(ape_result)\n",
    "            \n",
    "            print(\"Batch: \", batch_size_trial)\n",
    "            print(\"epoch: \", epochs_trial)\n",
    "            print(\"learning rate: \", learning_trial)\n",
    "            print(\"mse: \", mse)\n",
    "            print(\"akurasi, \", ape_result)\n",
    "            print(\"\")\n",
    "\n",
    "            SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[batch_size_trial, epochs_trial, learning_trial, mse, rounded_up]], columns=['batch_size', 'epochs', 'learning_rate', 'mse', 'akurasi']))\n",
    "\n",
    "# SearchResultsData.plot(x='parameter', y='mse', figsize=(15,4), kind='line')\n",
    "# SearchResultsData['batch_size'] = batch_size\n",
    "# SearchResultsData['epoch'] = epoch\n",
    "# SearchResultsData['mse'] = mse_list\n",
    "# print(SearchResultsData.head())\n",
    "SearchResultsData.to_excel(\"evaluasi_mse_with_learning_rate.xlsx\")\n",
    "\n",
    "# model.save(\"data/model.h5\")\n",
    "# print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General data analysis/plotting\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Data preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "# Neural Net modules\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "import matplotlib\n",
    "\n",
    "df = pd.read_excel(\"data.xlsx\")\n",
    "df = df[['Diagnosis', 'Tindakan', 'SEX', 'UMUR_TAHUN', 'LAMA_DIRAWAT', 'KELAS_RAWAT']]\n",
    "\n",
    "df['DiagnosisCAT'] = df['Diagnosis']\n",
    "df['Diagnosis'] = df['DiagnosisCAT'].astype('category')\n",
    "df['Diagnosis'] = df['Diagnosis'].cat.reorder_categories(df['DiagnosisCAT'].unique(), ordered=True)\n",
    "df['Diagnosis'] = df['Diagnosis'].cat.codes\n",
    "\n",
    "df['TindakanCAT'] = df['Tindakan']\n",
    "df['Tindakan'] = df['TindakanCAT'].astype('category')\n",
    "df['Tindakan'] = df['Tindakan'].cat.reorder_categories(df['TindakanCAT'].unique(), ordered=True)\n",
    "df['Tindakan'] = df['Tindakan'].cat.codes\n",
    "\n",
    "df.dropna(axis=0, inplace=True)\n",
    "\n",
    "X = df[['Diagnosis', 'Tindakan', 'SEX', 'UMUR_TAHUN', 'KELAS_RAWAT']].values\n",
    "y = df[['LAMA_DIRAWAT']].values\n",
    "\n",
    "### Sandardization of data ###\n",
    "PredictorScaler=StandardScaler()\n",
    "TargetVarScaler=StandardScaler()\n",
    "\n",
    "# # Storing the fit object for later reference\n",
    "PredictorScalerFit=PredictorScaler.fit(X)\n",
    "TargetVarScalerFit=TargetVarScaler.fit(y)\n",
    "\n",
    "# # Generating the standardized values of X and y\n",
    "X=PredictorScalerFit.transform(X)\n",
    "y=TargetVarScalerFit.transform(y)\n",
    "\n",
    "# Split the data into training and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "batch_size_list=[100, 150, 200, 250]\n",
    "epoch_list  =   [50, 100, 200, 500]\n",
    "\n",
    "# initializing the trials\n",
    "def createModel():\n",
    "    model = Sequential()\n",
    "    # Defining the first layer of the model\n",
    "    model.add(Dense(units=5, input_shape=(5,), kernel_initializer='normal', activation='relu'))\n",
    "\n",
    "    # Defining the Second layer of the model\n",
    "    model.add(Dense(units=60, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(units=60, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(units=5, kernel_initializer='normal', activation='relu'))\n",
    "\n",
    "\n",
    "    # The output neuron is a single fully connected node \n",
    "    # Since we will be predicting a single number\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='linear'))\n",
    "\n",
    "    # Compiling the model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "    return model\n",
    "\n",
    "model = KerasRegressor(model=createModel, verbose=0)\n",
    "\n",
    "param_grid = dict(batch_size=batch_size_list, epochs=epoch_list)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# summarize results\n",
    "grid_pred = grid_result.predict(X_test)\n",
    "\n",
    "gg = []\n",
    "for i in grid_pred:\n",
    "    gg.append(i)\n",
    "\n",
    "y_valid = y_test.copy()\n",
    "\n",
    "gf = pd.DataFrame(data=gg)\n",
    "# gf = gf.set_index(y_valid.index)\n",
    "gf.rename(columns={0: \"predicted\"}, inplace=True)\n",
    "df321 = pd.DataFrame(data=[[y_valid, gf]])\n",
    "df321.columns = [\"Y_true\", \"Y_pred\"]\n",
    "\n",
    "df321[\"Squared Error\"] = (df321[\"Y_true\"] - df321[\"Y_pred\"] )**2\n",
    "print(df321['Squared Error'].head())\n",
    "\n",
    "\n",
    "# print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "# means = grid_result.cv_results_['mean_test_score']\n",
    "# stds = grid_result.cv_results_['std_test_score']\n",
    "# params = grid_result.cv_results_['params']\n",
    "# for mean, stdev, param in zip(means, stds, params):\n",
    "#     print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "# from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_excel(\"data.xlsx\")\n",
    "df = df[['Diagnosis', 'Tindakan', 'SEX', 'UMUR_TAHUN', 'LAMA_DIRAWAT', 'KELAS_RAWAT']]\n",
    "\n",
    "df['DiagnosisCAT'] = df['Diagnosis']\n",
    "df['Diagnosis'] = df['DiagnosisCAT'].astype('category')\n",
    "df['Diagnosis'] = df['Diagnosis'].cat.reorder_categories(df['DiagnosisCAT'].unique(), ordered=True)\n",
    "df['Diagnosis'] = df['Diagnosis'].cat.codes\n",
    "\n",
    "df['TindakanCAT'] = df['Tindakan']\n",
    "df['Tindakan'] = df['TindakanCAT'].astype('category')\n",
    "df['Tindakan'] = df['Tindakan'].cat.reorder_categories(df['TindakanCAT'].unique(), ordered=True)\n",
    "df['Tindakan'] = df['Tindakan'].cat.codes\n",
    "\n",
    "df.dropna(axis=0, inplace=True)\n",
    "\n",
    "X = df[['Diagnosis', 'Tindakan', 'SEX', 'UMUR_TAHUN', 'KELAS_RAWAT']].values\n",
    "y = df[['LAMA_DIRAWAT']].values\n",
    "\n",
    "### Sandardization of data ###\n",
    "PredictorScaler=StandardScaler()\n",
    "TargetVarScaler=StandardScaler()\n",
    "\n",
    "# Storing the fit object for later reference\n",
    "PredictorScalerFit=PredictorScaler.fit(X)\n",
    "TargetVarScalerFit=TargetVarScaler.fit(y)\n",
    "\n",
    "# # Generating the standardized values of X and y\n",
    "X=PredictorScalerFit.transform(X)\n",
    "y=TargetVarScalerFit.transform(y)\n",
    "\n",
    "# Split the data into training and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "batch_size_list=[100, 150, 200, 250]\n",
    "epoch_list  =   [50, 100, 200, 500]\n",
    "\n",
    "SearchResultsData=pd.DataFrame(columns=['parameter', 'mse', 'akurasi'])\n",
    "\n",
    "# Function to create the model\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    # Defining the first layer of the model\n",
    "    model.add(Dense(units=5, input_shape=(5,), kernel_initializer='normal', activation='relu'))\n",
    "\n",
    "    # Defining the Second layer of the model\n",
    "    model.add(Dense(units=60, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(units=60, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(units=5, kernel_initializer='normal', activation='relu'))\n",
    "\n",
    "\n",
    "    # The output neuron is a single fully connected node \n",
    "    # Since we will be predicting a single number\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='linear'))\n",
    "\n",
    "    # Compiling the model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "\n",
    "model = KerasRegressor(model=create_model, verbose=0)\n",
    "\n",
    "# Define the hyperparameters grid\n",
    "param_grid = {'batch_size': batch_size_list,\n",
    "              'epochs': epoch_list}\n",
    "\n",
    "# Perform grid search\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# Get the results of grid search\n",
    "results = grid_result.cv_results_\n",
    "\n",
    "# Print MSE for each parameter combination\n",
    "for mean_score, params in zip(results[\"mean_test_score\"], results[\"params\"]):\n",
    "    model = KerasRegressor(model=create_model, verbose=0, **params)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Scaling the predicted Price data back to original price scale\n",
    "    y_pred_origin=TargetVarScalerFit.inverse_transform(y_pred)\n",
    "    \n",
    "    # Scaling the y_test Price data back to original price scale\n",
    "    y_test_origin=TargetVarScalerFit.inverse_transform(y_test)\n",
    "    \n",
    "    mse = mean_squared_error(y_pred= y_pred, y_true= y_test)\n",
    "\n",
    "    APE=100*(abs(y_test_origin - y_pred_origin)/y_test_origin)\n",
    "    ape_result = 100-np.mean(APE)\n",
    "    \n",
    "    # SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[ 'batch ' + str(params['batch_size']) + '-' + ' epoch ' + str(params['epochs']), mse, ape_result]], columns=['parameter', 'mse', 'akurasi']))\n",
    "    \n",
    "    print(\"Parameters: \", params)\n",
    "    print(\"Mean Squared Error: \", mse)\n",
    "    print(\"akurasi: \", ape_result)\n",
    "    print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rs_api",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
